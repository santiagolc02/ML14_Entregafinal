{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hc1nTPtVXyxm"
      },
      "source": [
        "#1. Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cargar los dos archivos (simplified_coffee.csv) y (synthetic_coffee_health_10000.csv) y ejecutar todo el código."
      ],
      "metadata": {
        "id": "RoWHhJUtb-ft"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0hr8aICXDKq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# NLTK\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Scikit-learn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    confusion_matrix, roc_auc_score, roc_curve, silhouette_score,\n",
        "    auc as sk_auc  # usado en la ROC multiclase\n",
        ")\n",
        "\n",
        "# Gensim\n",
        "try:\n",
        "    from gensim.models import Word2Vec\n",
        "    GENSIM_OK = True\n",
        "except Exception:\n",
        "    GENSIM_OK = False\n",
        "\n",
        "# Descarga/chequeo idempotente de recursos NLTK\n",
        "for pkg in (\"stopwords\", \"punkt\", \"wordnet\"):\n",
        "    try:\n",
        "        nltk.data.find(f\"corpora/{pkg}\" if pkg != \"punkt\" else \"tokenizers/punkt\")\n",
        "    except LookupError:\n",
        "        nltk.download(pkg, quiet=True)\n",
        "\n",
        "df2 = pd.read_csv(\"synthetic_coffee_health_10000.csv\")  # CSV de personas\n",
        "df2.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4suFXQ5JFuM"
      },
      "outputs": [],
      "source": [
        "# Cargar los CSV\n",
        "df1 = pd.read_csv(\"simplified_coffee.csv\")  # CSV de cafés\n",
        "df2 = pd.read_csv(\"synthetic_coffee_health_10000.csv\")  # CSV de personas\n",
        "\n",
        "# Limpiar espacios en los nombres de columnas\n",
        "df1.rename(columns=lambda x: x.strip(), inplace=True)\n",
        "df2.rename(columns=lambda x: x.strip(), inplace=True)\n",
        "\n",
        "# Verificar columnas\n",
        "print(\"Columnas df1:\", df1.columns)\n",
        "print(\"Columnas df2:\", df2.columns)\n",
        "\n",
        "# Merge usando columnas con nombres distintos\n",
        "merged_df = pd.merge(\n",
        "    df1,\n",
        "    df2,\n",
        "    left_on='loc_country',  # columna en df1\n",
        "    right_on='Country',     # columna en df2\n",
        "    how='inner'             # solo los registros que existan en ambos\n",
        ")\n",
        "\n",
        "# Opcional: eliminar columna duplicada 'Country' del df2\n",
        "merged_df.drop(columns=['Country'], inplace=True)\n",
        "\n",
        "# Mostrar resultado\n",
        "print(\"Filas del merge:\", len(merged_df))\n",
        "print(merged_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWfP6suQdNUC"
      },
      "outputs": [],
      "source": [
        "merged_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9lH3TNjX1Hm"
      },
      "source": [
        "#2. Preprocesamiento de texto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QcR2F4RqdaOe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Forzar descarga de recursos\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('wordnet', quiet=True)\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8N83_XDDdYNk"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "\n",
        "# Descargar todos los recursos necesarios\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFflI6uhc1Zi"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "    text = text.lower()  # minúsculas\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # eliminar caracteres no alfanuméricos\n",
        "    tokens = word_tokenize(text)  # tokenizar\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]  # stopwords + lematización\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "# Aplicar limpieza a la columna 'review'\n",
        "merged_df['review_clean'] = merged_df['review'].apply(clean_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQYHX3a0d6GY"
      },
      "outputs": [],
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def clean_text(text):\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "    # Minúsculas\n",
        "    text = text.lower()\n",
        "    # Eliminación de caracteres no alfanuméricos\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    # Tokenización usando word_tokenize importado directamente\n",
        "    tokens = word_tokenize(text)\n",
        "    # Eliminación de stopwords y lematización\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "# Limpiar columna 'review'\n",
        "merged_df['review_clean'] = merged_df['review'].apply(clean_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efbppMYKqjI4"
      },
      "outputs": [],
      "source": [
        "# Representación TF-IDF\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(merged_df['review_clean'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0H56HuvJql8o"
      },
      "outputs": [],
      "source": [
        "# Representación Word2Vec\n",
        "# Tokenizamos para Word2Vec\n",
        "sentences = [nltk.word_tokenize(text) for text in merged_df['review_clean']]\n",
        "\n",
        "# Entrenar modelo Word2Vec en nuestro dataset\n",
        "w2v_model = Word2Vec(sentences, vector_size=100, window=5, min_count=2, workers=4)\n",
        "\n",
        "#Obtener vector promedio de cada review\n",
        "def get_w2v_vector(tokens, model):\n",
        "    vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
        "    if len(vectors) == 0:\n",
        "        return np.zeros(model.vector_size)\n",
        "    return np.mean(vectors, axis=0)\n",
        "\n",
        "merged_df['review_w2v'] = [get_w2v_vector(nltk.word_tokenize(text), w2v_model)\n",
        "                            for text in merged_df['review_clean']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rvtGb5_qoQ-"
      },
      "outputs": [],
      "source": [
        "#Imprimir\n",
        "print(\"Merge completado. Shape del dataset:\", merged_df.shape)\n",
        "print(\"TF-IDF shape:\", tfidf_matrix.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUPH5wHDX4I2"
      },
      "source": [
        "#3. Modelado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fn8IBtgJVl6n"
      },
      "source": [
        "KNN (Clasificación)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I82iBQ66NGv3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.metrics import silhouette_score\n",
        "from scipy.stats import mode\n",
        "\n",
        "TARGET_COL = \"Health_Issues\"\n",
        "\n",
        "# 1) Filtrado y alineación con TF-IDF/W2V\n",
        "mask_valid = merged_df['review_clean'].fillna(\"\").str.len() > 0\n",
        "dfm = merged_df.loc[mask_valid].copy()\n",
        "idx = np.flatnonzero(mask_valid.values)\n",
        "\n",
        "# TF-IDF (índices válidos)\n",
        "X_tfidf = tfidf_matrix[idx]\n",
        "# W2V (apila los vectores por fila)\n",
        "X_w2v_f = np.vstack(dfm['review_w2v'].values)\n",
        "\n",
        "# 2) Etiqueta binaria o multiclase\n",
        "s_raw = dfm[TARGET_COL].astype(str).str.strip().str.lower()\n",
        "neg_set = {\"none\",\"no\",\"false\",\"0\",\"low\",\"none/low\",\"nan\",\"\"}\n",
        "pos_set = {\"yes\",\"true\",\"1\",\"mild\",\"moderate\",\"severe\",\"high\"}\n",
        "\n",
        "y_bin = s_raw.map(lambda x: (1 if x in pos_set else (0 if x in neg_set else np.nan)))\n",
        "if y_bin.isna().any():\n",
        "    y_num = pd.to_numeric(dfm[TARGET_COL], errors=\"coerce\")\n",
        "    y_bin = y_bin.where(~y_bin.isna(), (y_num > 0).astype(float))\n",
        "\n",
        "if y_bin.isna().any():\n",
        "    le = LabelEncoder()\n",
        "    y = le.fit_transform(dfm[TARGET_COL].astype(str).values)\n",
        "    classes_ = le.classes_\n",
        "else:\n",
        "    y = y_bin.astype(int).values\n",
        "    classes_ = np.array([0,1])\n",
        "\n",
        "n_classes = len(classes_)\n",
        "print(\"Etiquetas detectadas:\", classes_)\n",
        "\n",
        "# 3) Evaluación KNN (grid de K) + métricas + detalles para gráficas\n",
        "def eval_knn_grid_general(X, y, classes_, k_values=(3,5,7,9,11), test_size=0.25, seed=90989):\n",
        "    X_dense = X.toarray() if hasattr(X, \"toarray\") else np.asarray(X)\n",
        "    X_tr, X_te, y_tr, y_te = train_test_split(X_dense, y, test_size=test_size,\n",
        "                                              random_state=seed, stratify=y)\n",
        "    rows, details = [], {}\n",
        "    n_classes = len(classes_)\n",
        "    for k in k_values:\n",
        "        clf = KNeighborsClassifier(n_neighbors=k)\n",
        "        clf.fit(X_tr, y_tr)\n",
        "        y_pred = clf.predict(X_te)\n",
        "        y_score = clf.predict_proba(X_te) if hasattr(clf, \"predict_proba\") else None\n",
        "\n",
        "        acc = accuracy_score(y_te, y_pred)\n",
        "        prec = precision_score(y_te, y_pred, average=(\"binary\" if n_classes==2 else \"weighted\"), zero_division=0)\n",
        "        rec  = recall_score(y_te, y_pred, average=(\"binary\" if n_classes==2 else \"weighted\"), zero_division=0)\n",
        "        f1   = f1_score(y_te, y_pred, average=(\"binary\" if n_classes==2 else \"weighted\"), zero_division=0)\n",
        "\n",
        "        if y_score is not None:\n",
        "            if n_classes == 2:\n",
        "                auc_val = roc_auc_score(y_te, y_score[:,1])\n",
        "            else:\n",
        "                Y_bin = label_binarize(y_te, classes=np.arange(n_classes))\n",
        "                auc_val = roc_auc_score(Y_bin, y_score, multi_class=\"ovr\", average=\"macro\")\n",
        "        else:\n",
        "            auc_val = np.nan\n",
        "\n",
        "        cm = confusion_matrix(y_te, y_pred)\n",
        "        rows.append({\"k\": k, \"accuracy\": acc, \"precision\": prec, \"recall\": rec, \"f1\": f1, \"roc_auc\": auc_val})\n",
        "        details[k] = {\"y_test\": y_te, \"y_pred\": y_pred, \"y_score\": y_score, \"cm\": cm}\n",
        "\n",
        "    df_res = pd.DataFrame(rows).sort_values([\"f1\",\"accuracy\"], ascending=False).reset_index(drop=True)\n",
        "    best_k = int(df_res.iloc[0][\"k\"])\n",
        "    return df_res, best_k, details[best_k]\n",
        "\n",
        "def plot_confusion_matrix(cm, title=\"Confusion Matrix\"):\n",
        "    plt.figure()\n",
        "    plt.imshow(cm, interpolation='nearest')\n",
        "    plt.title(title); plt.xlabel(\"Predicted\"); plt.ylabel(\"True\")\n",
        "    plt.colorbar()\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            plt.text(j, i, str(cm[i, j]), ha='center', va='center')\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "def plot_roc_general(y_true, y_score, classes_, title=\"ROC Curve\"):\n",
        "    if y_score is None:\n",
        "        print(\"No hay probabilidades para ROC.\"); return\n",
        "    n_classes = len(classes_)\n",
        "    if n_classes == 2:\n",
        "        fpr, tpr, _ = roc_curve(y_true, y_score[:,1])\n",
        "        auc_val = roc_auc_score(y_true, y_score[:,1])\n",
        "        plt.figure()\n",
        "        plt.plot(fpr, tpr, linewidth=2); plt.plot([0,1],[0,1], \"--\")\n",
        "        plt.title(f\"{title} (AUC={auc_val:.3f})\")\n",
        "        plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\")\n",
        "        plt.tight_layout(); plt.show()\n",
        "    else:\n",
        "        from sklearn.metrics import auc as sk_auc\n",
        "        Y_bin = label_binarize(y_true, classes=np.arange(n_classes))\n",
        "        plt.figure()\n",
        "        aucs = []\n",
        "        for i in range(n_classes):\n",
        "            fpr, tpr, _ = roc_curve(Y_bin[:, i], y_score[:, i])\n",
        "            aucs.append(sk_auc(fpr, tpr))\n",
        "            plt.plot(fpr, tpr, label=f\"Clase {classes_[i]} (AUC={aucs[-1]:.2f})\")\n",
        "        plt.plot([0,1],[0,1], \"--\")\n",
        "        plt.title(f\"{title} (macro AUC={np.mean(aucs):.3f})\")\n",
        "        plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\")\n",
        "        plt.legend(); plt.tight_layout(); plt.show()\n",
        "\n",
        "# 4) Correr KNN en TF-IDF y en W2V\n",
        "res_knn_tfidf, best_k_tfidf, best_tf = eval_knn_grid_general(X_tfidf, y, classes_, k_values=(3,5,7,9,11))\n",
        "print(\"KNN (TF-IDF) – resultados:\"); display(res_knn_tfidf.round(3))\n",
        "print(\"Mejor k (TF-IDF):\", best_k_tfidf)\n",
        "plot_confusion_matrix(best_tf[\"cm\"], f\"Confusion – KNN TF-IDF (k={best_k_tfidf})\")\n",
        "plot_roc_general(best_tf[\"y_test\"], best_tf[\"y_score\"], classes_, f\"ROC – KNN TF-IDF (k={best_k_tfidf})\")\n",
        "\n",
        "res_knn_w2v, best_k_w2v, best_w2v = eval_knn_grid_general(X_w2v_f, y, classes_, k_values=(3,5,7,9,11))\n",
        "print(\"KNN (W2V) – resultados:\"); display(res_knn_w2v.round(3))\n",
        "print(\"Mejor k (W2V):\", best_k_w2v)\n",
        "plot_confusion_matrix(best_w2v[\"cm\"], f\"Confusion – KNN W2V (k={best_k_w2v})\")\n",
        "plot_roc_general(best_w2v[\"y_test\"], best_w2v[\"y_score\"], classes_, f\"ROC – KNN W2V (k={best_k_w2v})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIuur3bD68sZ"
      },
      "source": [
        "3.2 K-Means (Clustering)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11NxkJmnVFAt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score,confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def kmeans_analysis(X, k_min=2, k_max=10, seed=90989):\n",
        "    Xd = X.toarray() if hasattr(X, \"toarray\") else np.asarray(X)\n",
        "\n",
        "    # Métricas de clustering\n",
        "    inertia_vals, sil_vals, ch_vals, db_vals = [], [], [], []\n",
        "    models, labels_dict = {}, {}\n",
        "\n",
        "    for k in range(k_min, k_max+1):\n",
        "        km = KMeans(n_clusters=k, n_init=10, random_state=seed)\n",
        "        labels = km.fit_predict(Xd)\n",
        "\n",
        "        models[k] = km\n",
        "        labels_dict[k] = labels\n",
        "        inertia_vals.append(km.inertia_)\n",
        "\n",
        "        # Calcular métricas de clustering\n",
        "        try:\n",
        "            sil_vals.append(silhouette_score(Xd, labels))\n",
        "        except:\n",
        "            sil_vals.append(np.nan)\n",
        "\n",
        "        try:\n",
        "            ch_vals.append(calinski_harabasz_score(Xd, labels))\n",
        "        except:\n",
        "            ch_vals.append(np.nan)\n",
        "\n",
        "        try:\n",
        "            db_vals.append(davies_bouldin_score(Xd, labels))\n",
        "        except:\n",
        "            db_vals.append(np.nan)\n",
        "\n",
        "    # Crear DataFrame con métricas\n",
        "    metrics_df = pd.DataFrame({\n",
        "        'k': range(k_min, k_max+1),\n",
        "        'Inertia': inertia_vals,\n",
        "        'Silhouette': sil_vals,\n",
        "    }).set_index('k')\n",
        "\n",
        "    return metrics_df, models, labels_dict\n",
        "\n",
        "def plot_elbow(ks, inertia, title):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(ks, inertia, marker=\"o\", linestyle='-', color='b', linewidth=2)\n",
        "    plt.title(title, fontsize=14, fontweight='bold')\n",
        "    plt.xlabel(\"Número de clusters (k)\", fontsize=12)\n",
        "    plt.ylabel(\"Inertia (SSE)\", fontsize=12)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.xticks(ks)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_silhouette(ks, sil, title):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(ks, sil, marker=\"o\", linestyle='-', color='g', linewidth=2)\n",
        "    plt.title(title, fontsize=14, fontweight='bold')\n",
        "    plt.xlabel(\"Número de clusters (k)\", fontsize=12)\n",
        "    plt.ylabel(\"Silhouette Score\", fontsize=12)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.xticks(ks)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_all_metrics(metrics_df, title):\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "    fig.suptitle(f'{title} - Métricas de Clustering', fontsize=16, fontweight='bold')\n",
        "\n",
        "    k_values = metrics_df.index\n",
        "\n",
        "    # Inertia (Elbow Method)\n",
        "    axes[0,0].plot(k_values, metrics_df['Inertia'], marker='o', linestyle='-', color='b', linewidth=2)\n",
        "    axes[0,0].set_title('Método del Codo (Inertia)')\n",
        "    axes[0,0].set_xlabel('Número de clusters (k)')\n",
        "    axes[0,0].set_ylabel('Inertia (SSE)')\n",
        "    axes[0,0].grid(True, alpha=0.3)\n",
        "    axes[0,0].set_xticks(k_values)\n",
        "\n",
        "    # Silhouette Score\n",
        "    axes[0,1].plot(k_values, metrics_df['Silhouette'], marker='o', linestyle='-', color='g', linewidth=2)\n",
        "    axes[0,1].set_title('Silhouette Score')\n",
        "    axes[0,1].set_xlabel('Número de clusters (k)')\n",
        "    axes[0,1].set_ylabel('Silhouette Score')\n",
        "    axes[0,1].grid(True, alpha=0.3)\n",
        "    axes[0,1].set_xticks(k_values)\n",
        "\n",
        "# 1) Análisis de K-Means para TF-IDF y W2V\n",
        "print(\"ANÁLISIS K-MEANS - CLUSTERING NO SUPERVISADO\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Para TF-IDF\n",
        "print(\"\\nTF-IDF - Análisis de Clustering:\")\n",
        "metrics_tfidf, models_tfidf, labels_tfidf_all = kmeans_analysis(X_tfidf, 2, 10)\n",
        "\n",
        "plot_elbow(metrics_tfidf.index, metrics_tfidf['Inertia'], \"Método del Codo - TF-IDF\")\n",
        "plot_silhouette(metrics_tfidf.index, metrics_tfidf['Silhouette'], \"Silhouette Score - TF-IDF\")\n",
        "\n",
        "# Para W2V\n",
        "print(\"\\nW2V - Análisis de Clustering:\")\n",
        "metrics_w2v, models_w2v, labels_w2v_all = kmeans_analysis(X_w2v_f, 2, 10)\n",
        "\n",
        "plot_elbow(metrics_w2v.index, metrics_w2v['Inertia'], \"Método del Codo - W2V\")\n",
        "plot_silhouette(metrics_w2v.index, metrics_w2v['Silhouette'], \"Silhouette Score - W2V\")\n",
        "\n",
        "# 2) Interpretación de clusters\n",
        "def top_terms_tfidf(kmeans_model, vectorizer, topn=10):\n",
        "    centroids = kmeans_model.cluster_centers_\n",
        "    order = np.argsort(-centroids, axis=1)[:, :topn]\n",
        "    terms = np.array(vectorizer.get_feature_names_out())\n",
        "    return [[terms[j] for j in row] for row in order]\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"INTERPRETACIÓN DE CLUSTERS\")\n",
        "print(f\"{'='*60}\")\n",
        "\n",
        "# Para TF-IDF\n",
        "print(f\"\\nTF-IDF - Términos representativos (k={best_k_tfidf}):\")\n",
        "km_tfidf = models_tfidf[best_k_tfidf]\n",
        "labels_tfidf = labels_tfidf_all[best_k_tfidf]\n",
        "tfidf_top_terms = top_terms_tfidf(km_tfidf, tfidf_vectorizer, topn=8)\n",
        "\n",
        "for c, terms in enumerate(tfidf_top_terms):\n",
        "    print(f\"Cluster {c}: {', '.join(terms)}\")\n",
        "\n",
        "# 3) Distribución de clusters vs etiquetas reales\n",
        "if hasattr(y, '__len__'):\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"DISTRIBUCIÓN CLUSTERS vs ETIQUETAS REALES\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # Para TF-IDF\n",
        "    print(f\"\\nTF-IDF (k={best_k_tfidf}):\")\n",
        "    ct_tfidf = pd.crosstab(labels_tfidf, y, rownames=[\"Cluster\"], colnames=[\"Etiqueta Real\"])\n",
        "    print(ct_tfidf)\n",
        "\n",
        "    # Para W2V\n",
        "    print(f\"\\nW2V (k={best_k_w2v}):\")\n",
        "    km_w2v = models_w2v[best_k_w2v]\n",
        "    labels_w2v = labels_w2v_all[best_k_w2v]\n",
        "    ct_w2v = pd.crosstab(labels_w2v, y, rownames=[\"Cluster\"], colnames=[\"Etiqueta Real\"])\n",
        "    print(ct_w2v)\n",
        "\n",
        "# 4) Comparativa final entre representaciones\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"COMPARATIVA FINAL ENTRE REPRESENTACIONES\")\n",
        "print(f\"{'='*60}\")\n",
        "\n",
        "print(f\"\\nMejor k seleccionado:\")\n",
        "print(f\"TF-IDF: k = {best_k_tfidf}\")\n",
        "print(f\"W2V: k = {best_k_w2v}\")\n",
        "\n",
        "print(f\"\\nMétricas comparativas (para k óptimo de cada representación):\")\n",
        "print(f\"{'Métrica':<20} {'TF-IDF':<10} {'W2V':<10}\")\n",
        "print(\"-\" * 45)\n",
        "\n",
        "metrics_to_compare = ['Silhouette']\n",
        "for metric in metrics_to_compare:\n",
        "    tfidf_val = metrics_tfidf.loc[best_k_tfidf, metric]\n",
        "    w2v_val = metrics_w2v.loc[best_k_w2v, metric]\n",
        "\n",
        "    if metric == 'Davies_Bouldin':\n",
        "        # Para Davies-Bouldin, menor es mejor\n",
        "        better = \"TF-IDF\" if tfidf_val < w2v_val else \"W2V\"\n",
        "    else:\n",
        "        # Para otras métricas, mayor es mejor\n",
        "        better = \"TF-IDF\" if tfidf_val > w2v_val else \"W2V\"\n",
        "\n",
        "    print(f\"{metric:<20} {tfidf_val:.4f}    {w2v_val:.4f}    ← {better}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
        "                             f1_score, roc_auc_score, confusion_matrix, roc_curve)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1) Preparar etiquetas 0/1 desde dfm\n",
        "s_raw = dfm[\"Health_Issues\"].astype(str).str.strip().str.lower()\n",
        "neg_set = {\"none\",\"no\",\"false\",\"0\",\"low\",\"none/low\",\"nan\",\"\"}\n",
        "pos_set = {\"yes\",\"true\",\"1\",\"mild\",\"moderate\",\"severe\",\"high\"}\n",
        "y_all = s_raw.map(lambda x: 1 if x in pos_set else (0 if x in neg_set else np.nan))\n",
        "mask_valid = ~y_all.isna()\n",
        "y_vec = y_all[mask_valid].astype(int).values\n",
        "print(\"Número de muestras válidas:\", len(y_vec))\n",
        "print(\"Etiquetas detectadas:\", np.unique(y_vec))\n",
        "\n",
        "# 2) Features (asume que ya creaste X_tfidf, vectorizer, X_w2v_f)\n",
        "#    Filtramos las filas válidas para alinear con y_vec\n",
        "X_tfidf_clf = X_tfidf[mask_valid]      # si es sparse, este index funciona\n",
        "X_w2v_clf   = X_w2v_f[mask_valid]      # matriz densa (np.ndarray)\n",
        "\n",
        "# Sanity checks\n",
        "assert X_tfidf_clf.shape[0] == len(y_vec), \"X_tfidf_clf no alinea con y\"\n",
        "assert X_w2v_clf.shape[0]   == len(y_vec), \"X_w2v_clf no alinea con y\"\n",
        "\n",
        "# Vista de features TF-IDF si tienes 'vectorizer'\n",
        "try:\n",
        "    feature_names = vectorizer.get_feature_names_out()\n",
        "    print(\"Ejemplo de features TF-IDF:\", feature_names[:20], \"...\")\n",
        "    print(\"Total de features TF-IDF:\", len(feature_names))\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# 3) Función de entrenamiento y evaluación\n",
        "#    (convierte a denso para árboles si la X es sparse)\n",
        "from scipy import sparse\n",
        "\n",
        "def _make_compatible(model, X):\n",
        "    if isinstance(model, DecisionTreeClassifier) and sparse.issparse(X):\n",
        "        return X.toarray()\n",
        "    return X\n",
        "def train_eval_model(X, y, model, model_name):\n",
        "    X_tr, X_te, y_tr, y_te = train_test_split(\n",
        "        X, y, test_size=0.25, random_state=42, stratify=y\n",
        "    )\n",
        "    X_tr = _make_compatible(model, X_tr)\n",
        "    X_te = _make_compatible(model, X_te)\n",
        "\n",
        "    model.fit(X_tr, y_tr)\n",
        "    y_pred = model.predict(X_te)\n",
        "    y_score = model.predict_proba(X_te)[:,1] if hasattr(model, \"predict_proba\") else None\n",
        "    acc = accuracy_score(y_te, y_pred)\n",
        "    prec = precision_score(y_te, y_pred)\n",
        "    rec = recall_score(y_te, y_pred)\n",
        "    f1 = f1_score(y_te, y_pred)\n",
        "    auc_val = roc_auc_score(y_te, y_score) if y_score is not None else np.nan\n",
        "    cm = confusion_matrix(y_te, y_pred)\n",
        "    report = {\"accuracy\": acc, \"precision\": prec, \"recall\": rec, \"f1\": f1, \"roc_auc\": auc_val}\n",
        "    print(f\"\\n== {model_name} ==\")\n",
        "    print(f\"Accuracy: {acc:.3f}, Precision: {prec:.3f}, Recall: {rec:.3f}, F1: {f1:.3f}, AUC-ROC: {auc_val:.3f}\")\n",
        "    print(\"Confusion Matrix:\\n\", cm)\n",
        "\n",
        "    # ROC Curve\n",
        "    if y_score is not None:\n",
        "        fpr, tpr, _ = roc_curve(y_te, y_score)\n",
        "        plt.figure()\n",
        "        plt.plot(fpr, tpr, label=f\"{model_name} (AUC={auc_val:.3f})\")\n",
        "        plt.plot([0,1],[0,1], \"--\")\n",
        "        plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.title(f\"ROC Curve - {model_name}\")\n",
        "        plt.legend(); plt.show()\n",
        "    return report, auc_val, cm\n",
        "\n",
        "# 4) Definir modelos\n",
        "models = [\n",
        "    (LogisticRegression(max_iter=1000),                      \"LogisticRegression (TF-IDF)\"),\n",
        "    (DecisionTreeClassifier(max_depth=10, random_state=42),  \"DecisionTree (TF-IDF)\"),\n",
        "    (LogisticRegression(max_iter=1000),                      \"LogisticRegression (W2V)\"),\n",
        "    (DecisionTreeClassifier(max_depth=10, random_state=42),  \"DecisionTree (W2V)\")\n",
        "]\n",
        "\n",
        "# 5) Entrenar y guardar resultados\n",
        "results = {}\n",
        "for mdl, name in models:\n",
        "    X_input = X_tfidf_clf if \"TF-IDF\" in name else X_w2v_clf\n",
        "    report, auc_val, cm = train_eval_model(X_input, y_vec, mdl, name)\n",
        "    results[name] = {\"report\": report, \"auc\": auc_val, \"cm\": cm}\n",
        "\n",
        "# 6) Resumen de métricas\n",
        "metrics_df = pd.DataFrame({name: res[\"report\"] for name,res in results.items()}).T.round(3)\n",
        "print(\"\\n== Comparativa de modelos ==\")\n",
        "display(metrics_df)"
      ],
      "metadata": {
        "id": "Ifx9quATeQVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYWOvNC439Uj"
      },
      "source": [
        "## Implementación de GridSearchCV y/o RandomizedSearchCV."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nm7-4NlGvcAP"
      },
      "source": [
        "GridSearchCV conviene cuando el espacio de hiperparámetros es discreto y pequeño. Es exhaustivo y estable. Ej.: RandomForest (n_estimators, max_depth, etc.) con pocas opciones razonables.\n",
        "\n",
        "RandomizedSearchCV es mejor cuando el espacio es amplio/continuo o no sabemos bien las mejores regiones. Es eficiente con pocos intentos. Ej.: SVC (C, gamma) o XGBoost (learning_rate, max_depth…), donde hay rangos continuos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tl92TKFqHKpN"
      },
      "source": [
        "imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iMBqzgJW2H0k"
      },
      "outputs": [],
      "source": [
        "# Setup y utilidades para synthetic_coffee_health_10000.csv (target='Health_Issues')\n",
        "import os, time, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
        "from IPython.display import display\n",
        "\n",
        "# Model selection / pipelines / preprocessing\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Métricas\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Modelos\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# XGBoost\n",
        "try:\n",
        "    from xgboost import XGBClassifier\n",
        "except Exception:\n",
        "    import sys, subprocess\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"xgboost\"])\n",
        "    from xgboost import XGBClassifier\n",
        "\n",
        "SEED = 90989\n",
        "np.random.seed(SEED)\n",
        "\n",
        "def _ohe():\n",
        "    try:\n",
        "        return OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)  # sklearn >= 1.2\n",
        "    except TypeError:\n",
        "        return OneHotEncoder(handle_unknown=\"ignore\", sparse=False)         # sklearn < 1.2\n",
        "\n",
        "def _pre(X: pd.DataFrame) -> ColumnTransformer:\n",
        "    nums = X.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    cats = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
        "    return ColumnTransformer([\n",
        "        (\"num\", Pipeline([(\"imp\", SimpleImputer(strategy=\"median\")),\n",
        "                          (\"sc\",  StandardScaler())]), nums),\n",
        "        (\"cat\", Pipeline([(\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "                          (\"oh\",  _ohe())]), cats)\n",
        "    ])\n",
        "\n",
        "def _load_health():\n",
        "    csv_path = \"synthetic_coffee_health_10000.csv\"\n",
        "    if not os.path.exists(csv_path):\n",
        "        raise FileNotFoundError(f\"No encuentro {csv_path}\")\n",
        "\n",
        "    df = (pd.read_csv(csv_path)\n",
        "            .replace([np.inf, -np.inf], np.nan)\n",
        "            .dropna(axis=1, how=\"all\"))\n",
        "\n",
        "    target = \"Health_Issues\"\n",
        "    assert target in df.columns, f\"Target '{target}' no está en columnas: {df.columns.tolist()}\"\n",
        "    df = df[~df[target].isna()].copy()\n",
        "\n",
        "    y_raw = df[target]\n",
        "    X = df.drop(columns=[target])\n",
        "\n",
        "    if y_raw.nunique() == 2:\n",
        "        le = LabelEncoder()\n",
        "        y = pd.Series(le.fit_transform(y_raw), index=y_raw.index, name=target)\n",
        "        is_binary = True\n",
        "    else:\n",
        "        y = y_raw\n",
        "        is_binary = False\n",
        "\n",
        "    return X, y, csv_path, is_binary\n",
        "\n",
        "def _metrics_row(model_name, est, Xte, yte, is_binary, train_secs):\n",
        "    yhat = est.predict(Xte)\n",
        "    avg = \"binary\" if is_binary else \"macro\"\n",
        "    return {\n",
        "        \"model\": model_name,\n",
        "        \"accuracy\": accuracy_score(yte, yhat),\n",
        "        \"precision\": precision_score(yte, yhat, average=avg, zero_division=0),\n",
        "        \"recall\": recall_score(yte, yhat, average=avg, zero_division=0),\n",
        "        \"f1\": f1_score(yte, yhat, average=avg, zero_division=0),\n",
        "        \"train_time_s\": round(train_secs, 3)\n",
        "    }\n",
        "\n",
        "# Carga y split\n",
        "X, y, path, is_binary = _load_health()\n",
        "Xtr, Xte, ytr, yte = train_test_split(\n",
        "    X, y, test_size=0.2,\n",
        "    stratify=y if is_binary or (y.nunique() <= 20) else None,\n",
        "    random_state=SEED\n",
        ")\n",
        "\n",
        "pre = _pre(X)\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=SEED) if is_binary or (y.nunique() <= 20) else 3\n",
        "scoring = \"f1\" if is_binary else \"f1_macro\"\n",
        "\n",
        "print(f\"Dataset: {os.path.basename(path)} | target=Health_Issues | clases={y.nunique()} | CV=3 | métrica={scoring}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRiOakaxHMah"
      },
      "source": [
        "GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3TNdohdv2HvS"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Random Forest base\n",
        "rf = RandomForestClassifier(random_state=SEED, n_jobs=-1)\n",
        "\n",
        "# Pipeline: preprocesamiento -> modelo\n",
        "pipe_rf = Pipeline([(\"pre\", pre), (\"clf\", rf)])\n",
        "\n",
        "# Grid de hiperparámetros\n",
        "param_grid = {\n",
        "    \"clf__n_estimators\": [200, 500],\n",
        "    \"clf__max_depth\": [None, 10],\n",
        "    \"clf__min_samples_split\": [2, 10],\n",
        "    \"clf__min_samples_leaf\": [1, 2],\n",
        "    \"clf__max_features\": [\"sqrt\"],\n",
        "}\n",
        "\n",
        "# Búsqueda en rejilla\n",
        "# Si scoring es dict, deberías usar refit=\"f1_macro\" o \"f1\"\n",
        "gs = GridSearchCV(pipe_rf, param_grid, cv=cv, scoring=scoring, n_jobs=-1, refit=True)\n",
        "\n",
        "# Entrenar y medir tiempo\n",
        "t0 = time.time()\n",
        "gs.fit(Xtr, ytr)\n",
        "t_rf = time.time() - t0\n",
        "\n",
        "# Mejor modelo\n",
        "best_rf = gs.best_estimator_\n",
        "row_rf = _metrics_row(\"RandomForest (GridSearchCV)\", best_rf, Xte, yte,\n",
        "                      is_binary=is_binary, train_secs=t_rf)\n",
        "row_rf[\"cv_best_score\"] = round(gs.best_score_, 6)\n",
        "row_rf[\"best_params\"] = gs.best_params_\n",
        "\n",
        "print(\"== RandomForest (GridSearchCV) ==\")\n",
        "display(pd.DataFrame([row_rf]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkGv0hi9HVAe"
      },
      "source": [
        "RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4cDxFqV2Hk8"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "from scipy.stats import loguniform\n",
        "\n",
        "# SVC base (probability=True habilita ROC/AUC pero lo hace más lento)\n",
        "svc = SVC(probability=True, random_state=SEED)\n",
        "\n",
        "# Pipeline: preprocesamiento -> modelo\n",
        "pipe_svc = Pipeline([(\"pre\", pre), (\"clf\", svc)])\n",
        "\n",
        "# Distribuciones de búsqueda (espacios continuos con loguniform)\n",
        "param_dist = {\n",
        "    \"clf__C\": loguniform(1e-3, 1e2),\n",
        "    \"clf__gamma\": loguniform(1e-4, 1e-1),\n",
        "    \"clf__kernel\": [\"rbf\"],\n",
        "}\n",
        "\n",
        "# RandomizedSearchCV\n",
        "# Si 'scoring' es dict, usa refit=\"f1_macro\" o \"f1\" según corresponda\n",
        "rs = RandomizedSearchCV(\n",
        "    pipe_svc,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=20,\n",
        "    cv=cv,\n",
        "    scoring=scoring,\n",
        "    n_jobs=-1,\n",
        "    random_state=SEED,\n",
        "    refit=True,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "# Entrenar y medir tiempo\n",
        "t0 = time.time()\n",
        "rs.fit(Xtr, ytr)\n",
        "t_svc = time.time() - t0\n",
        "\n",
        "# Modelo\n",
        "best_svc = rs.best_estimator_\n",
        "row_svc = _metrics_row(\n",
        "    \"SVC (RandomizedSearchCV)\",\n",
        "    best_svc,\n",
        "    Xte,\n",
        "    yte,\n",
        "    is_binary=is_binary,   # <-- ajuste clave\n",
        "    train_secs=t_svc\n",
        ")\n",
        "row_svc[\"cv_best_score\"] = round(rs.best_score_, 6)\n",
        "row_svc[\"best_params\"]   = rs.best_params_\n",
        "\n",
        "print(\"== SVC (RandomizedSearchCV) ==\")\n",
        "display(pd.DataFrame([row_svc]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WPYiLt2HZoT"
      },
      "source": [
        "Visualización de métricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3nPJNyhEUeE"
      },
      "outputs": [],
      "source": [
        "# Comparación + métricas (con AUC si binario) + CM + ROC\n",
        "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
        "from IPython.display import display\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, ConfusionMatrixDisplay, RocCurveDisplay\n",
        ")\n",
        "\n",
        "# Helper para calcular fila de métricas (usa is_binary global si está disponible)\n",
        "def _metrics_row_with_roc(name, est, Xte, yte, is_binary_override=None):\n",
        "    # Usa el override (por ejemplo, la variable is_binary que definiste al cargar),\n",
        "    # y si no existe, lo infiere de yte\n",
        "    if is_binary_override is None:\n",
        "        is_binary_local = (len(np.unique(yte)) == 2)\n",
        "    else:\n",
        "        is_binary_local = bool(is_binary_override)\n",
        "\n",
        "    yhat = est.predict(Xte)\n",
        "    avg = \"binary\" if is_binary_local else \"macro\"\n",
        "    row = {\n",
        "        \"model\": name,\n",
        "        \"accuracy\": accuracy_score(yte, yhat),\n",
        "        \"precision\": precision_score(yte, yhat, average=avg, zero_division=0),\n",
        "        \"recall\":    recall_score(yte, yhat, average=avg, zero_division=0),\n",
        "        \"f1\":        f1_score(yte, yhat, average=avg, zero_division=0),\n",
        "        \"roc_auc\":   np.nan\n",
        "    }\n",
        "\n",
        "    # AUC solo si binario\n",
        "    if is_binary_local:\n",
        "        score = None\n",
        "        if hasattr(est, \"predict_proba\"):\n",
        "            score = est.predict_proba(Xte)[:, 1]\n",
        "        elif hasattr(est, \"decision_function\"):\n",
        "            score = est.decision_function(Xte)\n",
        "        if score is not None:\n",
        "            row[\"roc_auc\"] = roc_auc_score(yte, score)\n",
        "\n",
        "    return row, is_binary_local\n",
        "\n",
        "# 1) Tabla de métricas (agregamos AUC si corresponde)\n",
        "#    Pasamos is_binary si lo tienes definido en tu entorno; si no, no pasa nada.\n",
        "try:\n",
        "    row_rf, is_bin = _metrics_row_with_roc(\"RandomForest (Grid)\", best_rf, Xte, yte, is_binary_override=is_binary)\n",
        "    row_svc, _     = _metrics_row_with_roc(\"SVC (Randomized)\",   best_svc, Xte, yte, is_binary_override=is_binary)\n",
        "except NameError:\n",
        "    # Fallback si no existe is_binary en el entorno\n",
        "    row_rf, is_bin = _metrics_row_with_roc(\"RandomForest (Grid)\", best_rf, Xte, yte)\n",
        "    row_svc, _     = _metrics_row_with_roc(\"SVC (Randomized)\",   best_svc, Xte, yte)\n",
        "\n",
        "res = (pd.DataFrame([row_rf, row_svc])\n",
        "       .sort_values(by=[\"f1\", \"roc_auc\"], ascending=[False, False], na_position=\"last\")\n",
        "       .reset_index(drop=True))\n",
        "\n",
        "print(\"=== Métricas comparadas ===\")\n",
        "display(res[[\"model\", \"accuracy\", \"precision\", \"recall\", \"f1\", \"roc_auc\"]])\n",
        "\n",
        "# 2) Visualizaciones: Matriz de confusión + Curva ROC (si binario)\n",
        "for name, est in [(\"RandomForest (Grid)\", best_rf), (\"SVC (Randomized)\", best_svc)]:\n",
        "    # Matriz de confusión\n",
        "    ConfusionMatrixDisplay.from_estimator(est, Xte, yte)\n",
        "    plt.title(f\"Matriz de confusión — {name}\")\n",
        "    plt.show()\n",
        "\n",
        "    # Curva ROC (solo si es binario)\n",
        "    if is_bin:\n",
        "        if hasattr(est, \"predict_proba\"):\n",
        "            RocCurveDisplay.from_estimator(est, Xte, yte, name=name)\n",
        "        elif hasattr(est, \"decision_function\"):\n",
        "            RocCurveDisplay.from_estimator(est, Xte, yte, name=name)\n",
        "        plt.title(f\"Curva ROC — {name}\")\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4T0iPHXOoxi"
      },
      "outputs": [],
      "source": [
        "# Entrenamiento de modelos (LogReg, RandomForest+Grid, XGBoost+Randomized)\n",
        "import numpy as np, time, pandas as pd\n",
        "from IPython.display import display\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from scipy.stats import randint, uniform, loguniform\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Chequeo: esta sección asume que la Sección 1 ya definió estas variables:\n",
        "needed = [\"Xtr\",\"Xte\",\"ytr\",\"yte\",\"pre\",\"cv\",\"scoring\",\"SEED\",\"y\",\"is_binary\"]\n",
        "missing = [v for v in needed if v not in globals()]\n",
        "assert not missing, f\"Falta correr la Sección 1. Variables no definidas: {missing}\"\n",
        "\n",
        "def _row(name, est, Xte, yte, ttrain):\n",
        "    yhat = est.predict(Xte)\n",
        "    avg = \"binary\" if is_binary else \"macro\"\n",
        "    return {\n",
        "        \"model\": name,\n",
        "        \"accuracy\": accuracy_score(yte, yhat),\n",
        "        \"precision\": precision_score(yte, yhat, average=avg, zero_division=0),\n",
        "        \"recall\": recall_score(yte, yhat, average=avg, zero_division=0),\n",
        "        \"f1\": f1_score(yte, yhat, average=avg, zero_division=0),\n",
        "        \"train_time_s\": round(ttrain, 3),\n",
        "        \"cv_best_score\": np.nan,\n",
        "        \"best_params\": {}\n",
        "    }\n",
        "\n",
        "rows, models = {}, {}\n",
        "\n",
        "# 2.1 Regresión Logística (baseline)\n",
        "lr = LogisticRegression(max_iter=2000, random_state=SEED)\n",
        "pipe_lr = Pipeline([(\"pre\", pre), (\"clf\", lr)])\n",
        "t0 = time.time(); pipe_lr.fit(Xtr, ytr); t_lr = time.time() - t0\n",
        "rows[\"LogReg\"] = _row(\"LogisticRegression\", pipe_lr, Xte, yte, t_lr)\n",
        "models[\"LogisticRegression\"] = pipe_lr\n",
        "\n",
        "# 2.2 RandomForest + GridSearchCV\n",
        "rf = RandomForestClassifier(random_state=SEED, n_jobs=-1)\n",
        "pipe_rf = Pipeline([(\"pre\", pre), (\"clf\", rf)])\n",
        "param_grid = {\n",
        "    \"clf__n_estimators\": [200, 500],\n",
        "    \"clf__max_depth\": [None, 10],\n",
        "    \"clf__min_samples_split\": [2, 10],\n",
        "    \"clf__min_samples_leaf\": [1, 2],\n",
        "    \"clf__max_features\": [\"sqrt\"],\n",
        "}\n",
        "gs = GridSearchCV(pipe_rf, param_grid, cv=cv, scoring=scoring, n_jobs=-1, refit=True, verbose=0)\n",
        "t0 = time.time(); gs.fit(Xtr, ytr); t_rf = time.time() - t0\n",
        "best_rf = gs.best_estimator_\n",
        "row_rf = _row(\"RandomForest (GridSearchCV)\", best_rf, Xte, yte, t_rf)\n",
        "row_rf[\"cv_best_score\"] = round(gs.best_score_, 6)\n",
        "row_rf[\"best_params\"]   = gs.best_params_\n",
        "rows[\"RF\"] = row_rf\n",
        "models[\"RandomForest (GridSearchCV)\"] = best_rf\n",
        "\n",
        "# 2.3 XGBoost + RandomizedSearchCV\n",
        "if is_binary:\n",
        "    # Binario: sin LabelEncoder; objetivo binario\n",
        "    xgb = XGBClassifier(\n",
        "        objective=\"binary:logistic\",\n",
        "        eval_metric=\"logloss\",\n",
        "        tree_method=\"hist\",\n",
        "        random_state=SEED,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    pipe_xgb = Pipeline([(\"pre\", pre), (\"clf\", xgb)])\n",
        "    param_dist = {\n",
        "        \"clf__n_estimators\": randint(300, 800),\n",
        "        \"clf__max_depth\":    randint(3, 10),\n",
        "        \"clf__learning_rate\": loguniform(1e-3, 3e-1),\n",
        "        \"clf__subsample\":    uniform(0.6, 0.4),\n",
        "        \"clf__colsample_bytree\": uniform(0.6, 0.4),\n",
        "        \"clf__reg_lambda\":   loguniform(1e-2, 1e2),\n",
        "        \"clf__min_child_weight\": loguniform(1e-1, 10),\n",
        "    }\n",
        "    rs = RandomizedSearchCV(\n",
        "        pipe_xgb, param_distributions=param_dist, n_iter=20,\n",
        "        cv=cv, scoring=scoring, n_jobs=-1, random_state=SEED, refit=True, verbose=0\n",
        "    )\n",
        "    t0 = time.time(); rs.fit(Xtr, ytr); t_xgb = time.time() - t0\n",
        "    best_xgb = rs.best_estimator_\n",
        "    yhat_xgb = best_xgb.predict(Xte)\n",
        "else:\n",
        "    # Multiclase: LabelEncoder + objetivo multiclase\n",
        "    le = LabelEncoder().fit(pd.concat([ytr, yte], axis=0))\n",
        "    ytr_enc = le.transform(ytr)\n",
        "    xgb = XGBClassifier(\n",
        "        objective=\"multi:softprob\",\n",
        "        num_class=len(le.classes_),\n",
        "        eval_metric=\"mlogloss\",\n",
        "        tree_method=\"hist\",\n",
        "        random_state=SEED,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    pipe_xgb = Pipeline([(\"pre\", pre), (\"clf\", xgb)])\n",
        "    param_dist = {\n",
        "        \"clf__n_estimators\": randint(300, 800),\n",
        "        \"clf__max_depth\":    randint(3, 10),\n",
        "        \"clf__learning_rate\": loguniform(1e-3, 3e-1),\n",
        "        \"clf__subsample\":    uniform(0.6, 0.4),\n",
        "        \"clf__colsample_bytree\": uniform(0.6, 0.4),\n",
        "        \"clf__reg_lambda\":   loguniform(1e-2, 1e2),\n",
        "        \"clf__min_child_weight\": loguniform(1e-1, 10),\n",
        "    }\n",
        "    rs = RandomizedSearchCV(\n",
        "        pipe_xgb, param_distributions=param_dist, n_iter=20,\n",
        "        cv=cv, scoring=scoring, n_jobs=-1, random_state=SEED, refit=True, verbose=0\n",
        "    )\n",
        "    t0 = time.time(); rs.fit(Xtr, ytr_enc); t_xgb = time.time() - t0\n",
        "    best_xgb = rs.best_estimator_\n",
        "    yhat_xgb_enc = best_xgb.predict(Xte).astype(int)\n",
        "    yhat_xgb = le.inverse_transform(yhat_xgb_enc)\n",
        "\n",
        "row_xgb = {\n",
        "    \"model\": \"XGBoost (RandomizedSearchCV)\",\n",
        "    \"accuracy\": accuracy_score(yte, yhat_xgb),\n",
        "    \"precision\": precision_score(yte, yhat_xgb, average=(\"binary\" if is_binary else \"macro\"), zero_division=0),\n",
        "    \"recall\": recall_score(yte, yhat_xgb, average=(\"binary\" if is_binary else \"macro\"), zero_division=0),\n",
        "    \"f1\": f1_score(yte, yhat_xgb, average=(\"binary\" if is_binary else \"macro\"), zero_division=0),\n",
        "    \"train_time_s\": round(t_xgb, 3),\n",
        "    \"cv_best_score\": round(rs.best_score_, 6),\n",
        "    \"best_params\": rs.best_params_\n",
        "}\n",
        "rows[\"XGB\"] = row_xgb\n",
        "models[\"XGBoost (RandomizedSearchCV)\"] = best_xgb\n",
        "\n",
        "# Resumen\n",
        "res = (pd.DataFrame([rows[\"LogReg\"], rows[\"RF\"], rows[\"XGB\"]])\n",
        "       [[\"model\",\"accuracy\",\"precision\",\"recall\",\"f1\",\"train_time_s\",\"cv_best_score\",\"best_params\"]]\n",
        "       .sort_values(by=[\"f1\"], ascending=False)\n",
        "       .reset_index(drop=True))\n",
        "print(\"Comparación de los modelos.\")\n",
        "display(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3 personas falsas para verificar con nuestros 3 modelos"
      ],
      "metadata": {
        "id": "53XNyrJG9t8W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Personas dummy + predicciones 3 modelos\n",
        "# (tipos corregidos y columnas alineadas)\n",
        "import numpy as np, pandas as pd\n",
        "\n",
        "# --- Helpers ---\n",
        "def _estimate_binary_p(series: pd.Series) -> float:\n",
        "    \"\"\"Estimación de p(1) para columnas binarias (numéricas o texto tipo Yes/No).\"\"\"\n",
        "    s = series.dropna()\n",
        "    if s.empty:\n",
        "        return 0.5\n",
        "    if pd.api.types.is_numeric_dtype(s):\n",
        "        s = s.clip(0, 1)\n",
        "        return float(s.mean())\n",
        "    s = s.astype(str).str.lower().str.strip()\n",
        "    yes = {\"yes\", \"y\", \"true\", \"1\", \"si\", \"sí\"}\n",
        "    return float(s.isin(yes).mean()) if len(s) else 0.5\n",
        "\n",
        "def _build_dummy_rows_from_X(X: pd.DataFrame, n=3, seed=90989) -> pd.DataFrame:\n",
        "    \"\"\"Crea n filas dummy plausibles respetando tipos: Age/Heart_Rate/ID enteros, Smoking/Alcohol_Consumption binarios.\"\"\"\n",
        "    rng = np.random.default_rng(seed)\n",
        "    num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    cat_cols = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
        "\n",
        "    # columnas con tipo forzado\n",
        "    bin_cols = [c for c in [\"Smoking\", \"Alcohol_Consumption\"] if c in X.columns]\n",
        "    int_cols = [c for c in [\"Age\", \"Heart_Rate\", \"ID\"] if c in X.columns]\n",
        "\n",
        "    dummies = []\n",
        "    num_q = [0.2, 0.5, 0.8]  # tres perfiles\n",
        "\n",
        "    for i in range(n):\n",
        "        row = {}\n",
        "        # numéricas: cuantiles + jitter leve\n",
        "        for c in num_cols:\n",
        "            q = num_q[i % len(num_q)]\n",
        "            base = float(X[c].quantile(q))\n",
        "            span = float(X[c].max() - X[c].min())\n",
        "            jitter = (0.01 * span if span > 0 else 1e-3) * rng.normal(0, 0.3)\n",
        "            row[c] = base + jitter\n",
        "        # categóricas: top-k (hasta 3)\n",
        "        for c in cat_cols:\n",
        "            topk = X[c].value_counts(dropna=True).index.tolist()[:3]\n",
        "            if not topk:\n",
        "                if X[c].mode().empty:\n",
        "                    topk = [\"Unknown\"]\n",
        "                else:\n",
        "                    topk = [str(X[c].mode().iloc[0])]\n",
        "            row[c] = topk[i % len(topk)]\n",
        "        dummies.append(row)\n",
        "\n",
        "    df_dum = pd.DataFrame(dummies, columns=X.columns)\n",
        "\n",
        "    # Clip por cuantiles para evitar outliers raros\n",
        "    for c in num_cols:\n",
        "        lo, hi = X[c].quantile([0.01, 0.99])\n",
        "        df_dum[c] = df_dum[c].clip(lo, hi)\n",
        "\n",
        "    # Forzar enteros\n",
        "    for c in int_cols:\n",
        "        vals = np.abs(np.round(df_dum[c].fillna(0))).astype(int)\n",
        "        # Evitar IDs duplicados si existe 'ID'\n",
        "        if c == \"ID\":\n",
        "            vals += np.arange(1, len(vals) + 1)\n",
        "        df_dum[c] = vals\n",
        "\n",
        "    # Forzar binarias 0/1 según prevalencia del dataset\n",
        "    for c in bin_cols:\n",
        "        p = _estimate_binary_p(X[c])\n",
        "        p = float(np.clip(p, 0.05, 0.95))  # evita extremos 0/1 absolutos\n",
        "        df_dum[c] = np.random.default_rng(seed + 7).binomial(1, p, size=len(df_dum)).astype(int)\n",
        "\n",
        "    return df_dum\n",
        "\n",
        "def _align_to_pipeline_cols(est, df_row):\n",
        "    \"\"\"\n",
        "    Devuelve df_row (1 fila) con exactamente las columnas que el preprocesador del pipeline espera:\n",
        "    - agrega faltantes con NaN\n",
        "    - elimina extras\n",
        "    - reordena\n",
        "    \"\"\"\n",
        "    ct = est.named_steps[\"pre\"]  # ColumnTransformer\n",
        "    expected = []\n",
        "    for name, trans, cols in ct.transformers_:\n",
        "        if cols is not None and cols != 'drop':\n",
        "            expected.extend(list(cols))\n",
        "    # Agregar faltantes\n",
        "    for c in expected:\n",
        "        if c not in df_row.columns:\n",
        "            df_row[c] = np.nan\n",
        "    # Quedarse con esperadas y en ese orden\n",
        "    return df_row[expected]\n",
        "\n",
        "# --- Construir personas dummy (respeta tipos) ---\n",
        "personas = _build_dummy_rows_from_X(X, n=3, seed=SEED)\n",
        "personas.index = [f\"Persona_{i+1}\" for i in range(len(personas))]\n",
        "\n",
        "print(\"Predicciones usando nuestros modelos de datos falsos\")\n",
        "display(personas.head())\n",
        "\n",
        "# Guardar solo las primeras filas (head) como CSV\n",
        "personas.head().to_csv(\"personas_head.csv\", index=False)\n",
        "\n",
        "# Descargar el archivo\n",
        "files.download(\"personas_head.csv\")\n",
        "\n",
        "# --- Predicción con 3 modelos y mapeo mild -> 1 ---\n",
        "model_names = [\"LogisticRegression\", \"RandomForest (GridSearchCV)\", \"XGBoost (RandomizedSearchCV)\"]\n",
        "missing_models = [m for m in model_names if m not in models]\n",
        "assert not missing_models, f\"Faltan modelos entrenados en 'models': {missing_models}\"\n",
        "\n",
        "rows_pred = []\n",
        "for p_id, xrow in personas.iterrows():\n",
        "    X_one = xrow.to_frame().T\n",
        "    for mname in model_names:\n",
        "        est = models[mname]\n",
        "        # Alinear columnas a lo que el pipeline espera (evita error de columnas faltantes como 'ID')\n",
        "        X_one_aligned = _align_to_pipeline_cols(est, X_one.copy())\n",
        "        y_pred = est.predict(X_one_aligned)[0]\n",
        "        y_pred_out = 1 if str(y_pred).lower() == \"mild\" else y_pred\n",
        "        rows_pred.append({\n",
        "            \"persona\": p_id,\n",
        "            \"model\": mname,\n",
        "            \"pred_Health_Issues\": y_pred_out\n",
        "        })\n",
        "\n",
        "res_personas = pd.DataFrame(rows_pred).sort_values([\"persona\", \"model\"]).reset_index(drop=True)\n",
        "print(\"=== Predicciones por persona y modelo (target: Health_Issues, mild→1) ===\")\n",
        "display(res_personas)\n"
      ],
      "metadata": {
        "id": "buVp0PID_OqK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}